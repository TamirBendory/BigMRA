\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\newlabel{sec:intro}{{1}{1}{Introduction}{section.1}{}}
\citation{bendory2018toward}
\citation{lewicki1998review}
\citation{gogineni2017passive}
\citation{ljung1998system}
\citation{bendory2018toward}
\citation{aguerrebere2016fundamental}
\citation{jefferies1993restoration}
\citation{shalvi1990new}
\citation{ayers1988iterative}
\citation{abed1997blind}
\citation{ahmed2014blind}
\citation{li2016identifiability}
\citation{li2016rapid}
\citation{lee2017blind}
\citation{ling2017blind}
\citation{kuo2019geometry}
\newlabel{eq:model}{{1.1}{2}{Introduction}{equation.1.1}{}}
\@writefile{toc}{\contentsline {paragraph}{The well-separated model.}{3}{section*.2}}
\newlabel{eq:spacing}{{1.2}{3}{The well-separated model}{equation.1.2}{}}
\@writefile{toc}{\contentsline {paragraph}{The Poisson model.}{3}{section*.3}}
\newlabel{sec:extensions}{{1}{3}{Extensions}{section*.4}{}}
\newlabel{eq:heterogeneousdistribution}{{1.3}{3}{Extensions}{equation.1.3}{}}
\citation{frank2006three}
\citation{kuhlbrandt2014resolution}
\citation{bartesaghi20152}
\citation{scheres2012relion}
\citation{henderson1995limitations}
\citation{glaeser1999electron}
\@writefile{toc}{\contentsline {section}{\numberline {2}Connection with single-particle reconstruction via cryo-electron microscopy}{4}{section.2}}
\newlabel{sec:cryoem}{{2}{4}{Connection with single-particle reconstruction via cryo-electron microscopy}{section.2}{}}
\newlabel{eq:cryoEM}{{2.1}{4}{Connection with single-particle reconstruction via cryo-electron microscopy}{equation.2.1}{}}
\citation{vanheel1992correlation}
\citation{henderson2013avoiding}
\citation{vanheel2013finding}
\citation{shatsky2009method}
\citation{bendory2018toward}
\citation{kam1980reconstruction}
\citation{liu2013three}
\citation{kurta2017correlations}
\citation{levin20173d}
\citation{von2018structure}
\citation{bandeira2014multireference}
\citation{bendory2017bispectrum}
\citation{bandeira2017optimal}
\citation{perry2017sample}
\citation{bandeira2017estimation}
\citation{abbe2017multireference}
\citation{bendory2018toward}
\@writefile{toc}{\contentsline {section}{\numberline {3}Autocorrelation analysis}{5}{section.3}}
\newlabel{sec:AC_analysis}{{3}{5}{Autocorrelation analysis}{section.3}{}}
\citation{bendory2018toward}
\newlabel{eq:ac_general}{{3.1}{6}{Autocorrelation analysis}{equation.3.1}{}}
\newlabel{eq:ac_special}{{3.2}{6}{Autocorrelation analysis}{equation.3.2}{}}
\newlabel{eq:mixedautocorr}{{3.3}{6}{Autocorrelation analysis}{equation.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Autocorrelations under the well-separated model}{7}{subsection.3.1}}
\newlabel{eq:gamma}{{3.5}{7}{Autocorrelations under the well-separated model}{equation.3.5}{}}
\newlabel{eq:gamma_k}{{3.6}{7}{Autocorrelations under the well-separated model}{equation.3.6}{}}
\newlabel{eq:mean_micrograph}{{3.7}{7}{Autocorrelations under the well-separated model}{equation.3.7}{}}
\newlabel{eq:ac2_micrograph}{{3.8}{7}{Autocorrelations under the well-separated model}{equation.3.8}{}}
\newlabel{eq:ac3_micrograph}{{3.9}{7}{Autocorrelations under the well-separated model}{equation.3.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Autocorrelations under the Poisson model}{7}{subsection.3.2}}
\newlabel{sec:ac_poisson}{{3.2}{7}{Autocorrelations under the Poisson model}{subsection.3.2}{}}
\citation{bendory2017bispectrum}
\citation{boumal2017heterogeneous}
\citation{abbe2017multireference}
\newlabel{eq:mean_micrograph2}{{3.11}{8}{Autocorrelations under the Poisson model}{equation.3.11}{}}
\newlabel{eq:ac2_micrograph2}{{3.12}{8}{Autocorrelations under the Poisson model}{equation.3.12}{}}
\newlabel{eq:ac3_micrograph2}{{3.13}{8}{Autocorrelations under the Poisson model}{equation.3.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Theory}{8}{section.4}}
\newlabel{eq-uniqueness}{{4.1}{8}{Theory}{equation.4.1}{}}
\newlabel{prop:uniqueness}{{4.1}{8}{}{thm.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Guarantees for the homogeneous well-separated model}{9}{subsection.4.1}}
\newlabel{sec:theory_homogeneous_well_separated}{{4.1}{9}{Guarantees for the homogeneous well-separated model}{subsection.4.1}{}}
\newlabel{prop:gamma}{{4.2}{9}{}{thm.4.2}{}}
\newlabel{prop:gamma_sigma}{{4.3}{9}{}{thm.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Guarantees for the homogeneous Poisson model}{9}{subsection.4.2}}
\newlabel{sec:theory_homogeneous_poisson}{{4.2}{9}{Guarantees for the homogeneous Poisson model}{subsection.4.2}{}}
\newlabel{prop:uniqueness_poisson}{{4.5}{9}{}{thm.4.5}{}}
\citation{boumal2017heterogeneous}
\citation{bandeira2017estimation}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Elementary limitations of the heterogeneous case}{10}{subsection.4.3}}
\newlabel{sec:heterogeneity}{{4.3}{10}{Elementary limitations of the heterogeneous case}{subsection.4.3}{}}
\citation{bandeira2017estimation}
\citation{hayes1982reconstruction}
\citation{beinert2015ambiguities}
\citation{bendory2017fourier}
\citation{miao1999extending}
\citation{shechtman2015phase}
\citation{barnett2018geometry}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Autocorrelations in higher dimensions}{11}{subsection.4.4}}
\newlabel{sec:high_dimensions}{{4.4}{11}{Autocorrelations in higher dimensions}{subsection.4.4}{}}
\newlabel{eq:ac_d_dimension}{{4.6}{11}{Autocorrelations in higher dimensions}{equation.4.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Algorithms and numerical experiments}{12}{section.5}}
\newlabel{sec:numerics}{{5}{12}{Algorithms and numerical experiments}{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Experiment 1}{12}{subsection.5.1}}
\newlabel{sec:XP1}{{5.1}{12}{Experiment 1}{subsection.5.1}{}}
\citation{boumal2017heterogeneous}
\citation{manopt}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Experiment described in Section\nobreakspace  {}\ref  {sec:XP1}. For a fixed noise level $\sigma = 3$ and a fixed set of $K = 3$ signals of length $L = 21$, an observation $y$ of length $N = 1.23 \cdot 10^{10}$ is generated according to\nobreakspace  {}\textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces \ref  {eq:model}\unskip \@@italiccorr )}} in the well-separated model, with fixed occurrence probabilities. Each row corresponds to one of the signals. The last column shows evolution of the relative root mean squared error in estimating each signal, as a longer and longer subset of $y$ is observed. Red dots mark the three snapshots that are illustrated in columns 1--3: red signals are the ground truth and blue signals are the estimators.\relax }}{13}{figure.caption.5}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:1Dheterosignals}{{1}{13}{Experiment described in Section~\ref {sec:XP1}. For a fixed noise level $\sigma = 3$ and a fixed set of $K = 3$ signals of length $L = 21$, an observation $y$ of length $N = 1.23 \cdot 10^{10}$ is generated according to~\eqref {eq:model} in the well-separated model, with fixed occurrence probabilities. Each row corresponds to one of the signals. The last column shows evolution of the relative root mean squared error in estimating each signal, as a longer and longer subset of $y$ is observed. Red dots mark the three snapshots that are illustrated in columns 1--3: red signals are the ground truth and blue signals are the estimators.\relax }{figure.caption.5}{}}
\newlabel{eq:optim1D}{{5.1}{13}{Experiment 1}{equation.5.1}{}}
\citation{perry2017sample}
\citation{boumal2017heterogeneous}
\citation{boumal2017heterogeneous}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Experiment 2}{14}{subsection.5.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces In the $N \to \infty $ regime (access to exact autocorrelations, excluding biased entries) and with known uniform densities, it seems that $K$ up to $\sqrt  {L}$ (red curve) i.i.d.\ Gaussian signals of length $L$ can be recovered from the known moments. CPU time is in seconds. Strictly above red dots, recovery is impossible because the number of unknowns exceeds the number of computed autocorrelations; see Section\nobreakspace  {}\ref  {sec:heterogeneity}. Similarly to\nobreakspace  {}\cite  [Fig.\nobreakspace  {}4.1]{boumal2017heterogeneous}, this experiment suggests a possible statistical-computational gap.\relax }}{15}{figure.caption.6}}
\newlabel{fig:KLXP}{{2}{15}{In the $N \to \infty $ regime (access to exact autocorrelations, excluding biased entries) and with known uniform densities, it seems that $K$ up to $\sqrt {L}$ (red curve) i.i.d.\ Gaussian signals of length $L$ can be recovered from the known moments. CPU time is in seconds. Strictly above red dots, recovery is impossible because the number of unknowns exceeds the number of computed autocorrelations; see Section~\ref {sec:heterogeneity}. Similarly to~\cite [Fig.~4.1]{boumal2017heterogeneous}, this experiment suggests a possible statistical-computational gap.\relax }{figure.caption.6}{}}
\citation{boumal2017heterogeneous}
\citation{boumal2017heterogeneous}
\citation{weinthesis}
\citation{bandeira2017estimation}
\citation{elser2017rrr}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Experiment 3}{16}{subsection.5.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces  Example of observations for the 2-D experiment (of size $250\times 250$) with additive white Gaussian noise of variance $\sigma ^2$ for increasing values of $\sigma $. Each observation contains the same four occurrences of a $50 \times 50$ image of Einstein. In panel (c), the noise level is such that it is challenging to detect the planted images.\relax }}{17}{figure.caption.7}}
\newlabel{fig:micro_example}{{3}{17}{Example of observations for the 2-D experiment (of size $250\times 250$) with additive white Gaussian noise of variance $\sigma ^2$ for increasing values of $\sigma $. Each observation contains the same four occurrences of a $50 \times 50$ image of Einstein. In panel (c), the noise level is such that it is challenging to detect the planted images.\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces  Recovery of Einstein from observations at noise level $\sigma = 3$ (see Figure\nobreakspace  {}\ref  {fig:micro_example}(c)). Averaged autocorrelations of the data allow to estimate the power spectrum of the target image. This does not require locating the signal occurrences. The RRR algorithm produces the estimates, obtained from $2\times 10^2,2\times 10^3,2\times 10^4$ and $2\times 10^5$ observations (growing across panels from left to right).\relax }}{17}{figure.caption.8}}
\newlabel{fig:Einst_example}{{4}{17}{Recovery of Einstein from observations at noise level $\sigma = 3$ (see Figure~\ref {fig:micro_example}(c)). Averaged autocorrelations of the data allow to estimate the power spectrum of the target image. This does not require locating the signal occurrences. The RRR algorithm produces the estimates, obtained from $2\times 10^2,2\times 10^3,2\times 10^4$ and $2\times 10^5$ observations (growing across panels from left to right).\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Summary}{17}{section.6}}
\citation{lan2019multi}
\citation{bendory2018toward}
\citation{bendory2018toward}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Relative error curve for Experiment 3 in Figure\nobreakspace  {}\ref  {fig:Einst_example}. Each observation contains about 700 image occurrences at unknown locations.\relax }}{18}{figure.caption.9}}
\newlabel{fig:error_per_micro}{{5}{18}{Relative error curve for Experiment 3 in Figure~\ref {fig:Einst_example}. Each observation contains about 700 image occurrences at unknown locations.\relax }{figure.caption.9}{}}
\bibstyle{plain}
\bibdata{ref}
\bibcite{abbe2017multireference}{1}
\bibcite{abed1997blind}{2}
\bibcite{aguerrebere2016fundamental}{3}
\bibcite{ahmed2014blind}{4}
\bibcite{ayers1988iterative}{5}
\bibcite{bandeira2017optimal}{6}
\bibcite{bandeira2017estimation}{7}
\bibcite{bandeira2014multireference}{8}
\bibcite{barnett2018geometry}{9}
\bibcite{bartesaghi20152}{10}
\bibcite{beinert2015ambiguities}{11}
\bibcite{bendory2017fourier}{12}
\bibcite{bendory2018toward}{13}
\bibcite{bendory2017bispectrum}{14}
\bibcite{manopt}{15}
\bibcite{boumal2017heterogeneous}{16}
\bibcite{elser2017rrr}{17}
\bibcite{frank2006three}{18}
\bibcite{glaeser1999electron}{19}
\bibcite{gogineni2017passive}{20}
\bibcite{hayes1982reconstruction}{21}
\bibcite{henderson1995limitations}{22}
\bibcite{henderson2013avoiding}{23}
\bibcite{jefferies1993restoration}{24}
\bibcite{kam1980reconstruction}{25}
\bibcite{kuhlbrandt2014resolution}{26}
\bibcite{kuo2019geometry}{27}
\bibcite{kurta2017correlations}{28}
\bibcite{lan2019multi}{29}
\bibcite{lee2017blind}{30}
\bibcite{levin20173d}{31}
\bibcite{lewicki1998review}{32}
\bibcite{li2016rapid}{33}
\bibcite{li2016identifiability}{34}
\bibcite{ling2017blind}{35}
\bibcite{liu2013three}{36}
\bibcite{ljung1998system}{37}
\bibcite{miao1999extending}{38}
\bibcite{perry2017sample}{39}
\bibcite{scheres2012relion}{40}
\bibcite{shalvi1990new}{41}
\bibcite{shatsky2009method}{42}
\bibcite{shechtman2015phase}{43}
\bibcite{vanheel2013finding}{44}
\bibcite{vanheel1992correlation}{45}
\bibcite{von2018structure}{46}
\bibcite{weinthesis}{47}
\@writefile{toc}{\contentsline {section}{\numberline {A}Autocorrelations in the well-separated model}{23}{appendix.A}}
\newlabel{sec:autocorrelation_computation}{{A}{23}{Autocorrelations in the well-separated model}{appendix.A}{}}
\newlabel{eq:explicityiindicators}{{A.1}{23}{Autocorrelations in the well-separated model}{equation.A.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B}Autocorrelations in the Poisson model}{26}{appendix.B}}
\newlabel{sec:proof_prop_poisson}{{B}{26}{Autocorrelations in the Poisson model}{appendix.B}{}}
\newlabel{lem-choose}{{B.1}{26}{}{thm.B.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.1}Computing $a_y^1$}{27}{subsection.B.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.2}Computing $a_y^2$}{27}{subsection.B.2}}
\newlabel{moment2-condm}{{B.12}{28}{Computing $a_y^2$}{equation.B.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.3}Computing $a_x^3$}{28}{subsection.B.3}}
\newlabel{case1}{{1}{29}{Computing $a_x^3$}{Item.15}{}}
\newlabel{case2}{{2}{29}{Computing $a_x^3$}{Item.16}{}}
\newlabel{case3}{{3}{29}{Computing $a_x^3$}{Item.17}{}}
\newlabel{case4}{{4}{29}{Computing $a_x^3$}{Item.18}{}}
\newlabel{case5}{{5}{29}{Computing $a_x^3$}{Item.19}{}}
\newlabel{aaaa}{{B.18}{29}{Computing $a_x^3$}{equation.B.18}{}}
\newlabel{bbbb}{{B.20}{30}{Computing $a_x^3$}{equation.B.20}{}}
\newlabel{cccc}{{B.21}{30}{Computing $a_x^3$}{equation.B.21}{}}
\newlabel{dddd}{{B.22}{30}{Computing $a_x^3$}{equation.B.22}{}}
\newlabel{eeee}{{B.23}{30}{Computing $a_x^3$}{equation.B.23}{}}
\newlabel{ffff}{{B.26}{31}{Computing $a_x^3$}{equation.B.26}{}}
\newlabel{gggg}{{B.27}{31}{Computing $a_x^3$}{equation.B.27}{}}
\newlabel{hhhh}{{B.28}{31}{Computing $a_x^3$}{equation.B.28}{}}
\newlabel{iiii}{{B.29}{31}{Computing $a_x^3$}{equation.B.29}{}}
\newlabel{jjjj}{{B.30}{31}{Computing $a_x^3$}{equation.B.30}{}}
\newlabel{kkkk}{{B.31}{31}{Computing $a_x^3$}{equation.B.31}{}}
\newlabel{llll}{{B.33}{31}{Computing $a_x^3$}{equation.B.33}{}}
\@writefile{toc}{\contentsline {section}{\numberline {C}Proof of Proposition\nobreakspace  {}\ref  {prop:gamma}}{32}{appendix.C}}
\newlabel{sec:proof_prop_gamma}{{C}{32}{Proof of Proposition~\ref {prop:gamma}}{appendix.C}{}}
\@writefile{toc}{\contentsline {section}{\numberline {D}Proof of Proposition\nobreakspace  {}\ref  {prop:gamma_sigma}}{33}{appendix.D}}
\newlabel{sec:proof_prop_gamma_sigma}{{D}{33}{Proof of Proposition~\ref {prop:gamma_sigma}}{appendix.D}{}}
\newlabel{eq:E1}{{D.1}{33}{Proof of Proposition~\ref {prop:gamma_sigma}}{equation.D.1}{}}
\newlabel{eq:E2}{{D.2}{33}{Proof of Proposition~\ref {prop:gamma_sigma}}{equation.D.2}{}}
\newlabel{eq:E12}{{D.3}{33}{Proof of Proposition~\ref {prop:gamma_sigma}}{equation.D.3}{}}
\newlabel{eq:sigma2}{{D.4}{33}{Proof of Proposition~\ref {prop:gamma_sigma}}{equation.D.4}{}}
\newlabel{eq:quad1}{{D.5}{33}{Proof of Proposition~\ref {prop:gamma_sigma}}{equation.D.5}{}}
\newlabel{eq:E3}{{D.6}{33}{Proof of Proposition~\ref {prop:gamma_sigma}}{equation.D.6}{}}
\newlabel{eq:quad2}{{D.8}{34}{Proof of Proposition~\ref {prop:gamma_sigma}}{equation.D.8}{}}
\newlabel{eq:cond}{{D.9}{35}{Proof of Proposition~\ref {prop:gamma_sigma}}{equation.D.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {E}Proof of Proposition\nobreakspace  {}\ref  {prop:uniqueness_poisson}}{35}{appendix.E}}
\newlabel{sec:proof_uniqueness_poisson}{{E}{35}{Proof of Proposition~\ref {prop:uniqueness_poisson}}{appendix.E}{}}
